1. AI FOUNDATIONS


   1. Intro to AI
What is Artificial Intelligence? 
The ability of machines to mimic the cognitive abilities and problem-solving capabilities of human intelligence.
Human Intelligence is the capability of humans to allow us to learn new skills through observation; think abstractly and reason; communicate using a language and non-verbal cues; handle complex situations in real time; plans short and long term; creates art, music and inventions.
If we can replicate any of these capabilities in machines, that is Artificial General Intelligence (AGI). When we apply AGI to solve problems with specific, narrow objectives, we call it Artificial Intelligence (AI).
AI examples: Classifying images, spam mail classification, writing computer language code, predicting old car prices.
AI terminology: Machine Learning, Deep Learning, Data Science.
Why do we need AI?
Automation and Decision Making: Approve a credit card or loan, process insurance claims, recommend products to customers, detect fraudulent transactions, classify documents and images.
Creative Support: Create content, write stories and poems, provide designs, share code, generate ideas, crack jokes.




   2. AI – Tasks and Data
Commonly Used AI Domains: Language, Audio and Speech, Vision.
Language-Related AI Tasks
Language-related AI tasks can be text-related or generative AI. Text-related tasks use text as input, and the output can vary depending on the tasks.
Examples: Detect language, Extract in a text, extract key phrases, understand sentiment of a text, classify text based on content, translate text.
Gen AI tasks, they are generative which means the output text is generated by a model. 
Examples: Creating a story, poem, etc; summarize text, answer questions, generate image captions, complete text, convert text to speech.


Text as Data:
Text is inherently sequential, and text consists of sentences. Sentences can have multiple words and those words need to be converted to numbers for it to be used to train language models. It is known as tokenization. The length of the sentences can vary and all the sentences lengths need to be made equal. This is done through padding. Words can have similarities with other words, and sentences can also be similar to other sentences. Similarity can be measured through dot similarity or cosine similarity or embedding.
Language AI models are specifically designed to understand, process and generate natural language. These models have been trained on vast amounts of textual data that can perform various Natural Language Processing, or NLP tasks. The task that needs to be performed, the size , the type of input and output. The deep learning architectures used to train models that perform language tasks are:
Recurrent Neural Networks: Processes data sequentially and stores hidden states.
Long Short-Term Memory: Processes data sequentially and can retain the context better through use of gates.
Transformers: Processes data in parallel. Use concept of self-attention to better understand the context.
Speech-related AI tasks can be either audio-related or generative AI. Turn speech to text, recognize speaker, perform voice conversion, recognize speech emotions, turn text to speech. GenerativeAI tasks: music composition, speech synthesis.


Audio and Speech as Data
Audio or speech is digitized as snapshots taken in time. The sample rate is the number of times in a second an audio sample is taken. 
Digitized Snapshots in time, sample rate of 44.1kHz(sound reconstructed at 44100 tunes per sec), and when the audio is played, the hardware then reconstructs the sound 44000 times per second. The bit depth is the number of bits in each of the 441000 audio pieces or how information rich of each of those 44100 audio pieces is.
However, nothing much can be inferred by looking at just one audio sample. Multiple samples need to be correlated to make sense of the data. For example, listening to a song for a fraction of a second, you won’t be able to infer much about the song.
Audio and speech AI modoles are designed to process and manipulate audio and speech. These deep learning model architectures are used to train and perform language tasks: Recurrent Neural Networks, Long short-term memory, transformers, variational autoencoders, waverform models, Siamese networks.


Vision Related AI Tasks
Could be image-related or generative AI. Image-related AI tasks classify image, identify objects in an image, identify boundaries in an image, extract text in an image, count objects in an image. Facial recognition is one of the most popular image-related tasks that is often used as surveillance and tracking of people in real time and it’s is used in a lot of different fields, including security, biometrics, law enforcement and social media. 
Gen AI Tasks: Create image from a text, generate images of specific style, Generate high-resolution images, repair damaged images, perform image to image translation, get 3D views from 2D sketches.
Images as data:
Images consist of pixels and pixels can be either grayscale or color, and we can’t really make out what an image is just by looking at one pixel.
Vision AI models: AI models designed to process and understand visual information from images and videos. Convolutional Neural Networks-> Detects patterns in images, learning hierarchical representations of visual features. YOLO-> You only look once. Processes the image and detects objects within the image. Generative Adversarial Networks: Generates real-looking images.


Other AI tasks:
Anomaly Detection: Detects anomalies in time series data. Example: fraud detection, machine failure, etc.
Recommendations: Recommends products using data of similar products or users. Example: ecommerce websites.
Forecasting: Forscasts a future event or value using past data. Can be used for weather forecasting and predicting the stock price.




   3. AI vs ML vs DL
Relationship between AI, ML, and DL
Artifitial intelligence
Machines imitates human intelligence. AI referes to the broader concept of crating machines or systems that can perform tasks that typically require human Intelligence.


Machine learning
Algorithms learn from past data and predict outcome on new data or to identify trends from past data. ML is a subset of AI that focuses on the development of algorithms that enable machines to learn from and make predictions or decisions based on data.
An algorithm refers to a specific set of rules, mathematical equations, or procedures that the machine learning model follows to learn from data and make predictions on.
Several types of machine learning:
* Supervised: Extracting rules from data.
Train a model to predict outcomes. Through the process of training a model can be built to have a specific intelligence to do a specific task.
Through a process of training, a model can be built that will have a specific intelligence to do a specific task. 
The algorithm incrementally updates the model by looking at the data samples. Once built the model can be used to predict an outcome on a new data.
Supervised learning = learning for labeled data


* Unsupervised: Extracting trends from data.
Data does not have a specific outcome or label. Discovering trends in data can provide insights. Similar data can be grouped into clusters.Gain insights by clustering data.
Exploring patterns and data and grouping similar data into clusters drives unsupervised machine learning.


* Reinforcement Learning: Solving tasks by trial and error.
Decision, feedback, learning. Reinforcement learning learn by reward. It learns to make decisions by trying different actions and receiving feedback. RL is a machine learning approach where a computer program learns to make decisions by trying different actions and receiving feedback. It teaches agents how to solve tasks by trial and error. This approach is used in Autonomous car driving and robots as well. 


Deep Learning
Algorithms learn from complex data using neural networks and predict outcomes or generate new data. Subfield of ML that uses neural networks with many layers, deep neural networks, to learn and make sense of complex patterns in data. Deep Learning is all about extracting features and rules from data. Focuses on training neural networks with multiple layers, allowing them to automatically learn and extract complex features and rules from data.
Neural Networks: Made up of interconnected nodes or neurons in a layered structure that resembles the human brain. function approximation is a technique for estimating an unknown underlying function using historical observations from the domain.


Generative AI: Machine Learning that can produce content such as audio, text, code, video, images, and other data. These models, often powered by neural networks, learn patterns from existing data to craft fresh and creative output.
















2. ML FOUNDATIONS


   4. Intro to ML
ML is a subset of artificial intelligence that focuses on creating computer systems that can learn and improve from experience. ML provides statistical tools to analyze, visualize, and make predictions from data. Online shopping, Netflix movie suggestions, spam mail warning, self-driving cars.
Input features, output labels.
The types of ML labels depend on whether we have a labeled output or not. In general, there are 3 types:
* Supervised: labeled data is used to train the model. Classify or make predictions.
* Unsupervised learning is generally used to understand relationships within a data set. Labels are not used or not available.
* Reinforcement learning uses algorithms that learn from outcomes to make decisions or choices.
Machine Learning Use Cases:
* Supervised: Disease detection, weather forecasting, stock price prediction, spam detection, credit scoring.
* Unsupervised: Fraudulent transactions detection, customer segmentation, outlier detection, targeted marketing campaigns.
* Reinforcement: Automated robots, autonomous cars, video games, healthcare.


   5. Supervised learning - Regression
Machine learning model that learns from labeled data. The model learns the mapping between the input and the output.
Application examples: House price prediction, disease detection, sentiment analysis, stock price prediction.
In supervised learning the mapping between input and output is fundamental. It involves teaching a model to learn the relationship between input data and corresponding output or target values. In supervised learning the output can be either categorical or continuous. When the output is continuous, we use regression(house price prediction), and when the output is categorical, we use classification(Spam Detector).
In house price prediction, when making the graph between house size and its price consqutively, the equation for this function is given by f of x equal to w multiplied by x plus b, where w is the slope of the line and b is the y-intercept. The slope in this case is the rate of change of house price with respect to the house size.
  





Machine learning algorithm, linear regression in this case, adjusts the positioning of the line by changing the values of the weight and bias. This is done so that the difference between the predicted and actual value is reduced. The difference between the predicted and actual value is called error. Loss is a number indicating how far the predicted value is from the actual value. Loss is the penalty for a bad prediction. Loss is a number indicating how far the predicted value is from the actual value. If the prediction of a model is perfect, the loss is zero, else the loss is high. One of the ways to calculate loss is to take a difference between predicted and actual value and square it.
Squared error is the error difference between the predicted point and the actual data point, which needs to be minimized during training. 
The algorithm iteratively adjusts the weights and bias to minimize the squared loss. Once we arrive at the optimal value of the weight and bias, the model can be used for prediction.
To summarize, we train a regression model by giving input and output value pairs, which we call as data set. The algorithm learns a function f, which is the mapping function. This represents the trained model. This function is used for prediction. If we give house size as input to the trained model, the learned function can predict a house price.




   6. Supervised learning - Classification
In supervised learning, the output can be either categorical or continuous. When the output is continuous, we use regression to predict a numeric output. When the output is categorical, we use classification to predict a category or a label. 
Classification is a supervised learning problem where the goal is to assign a category or label to the outcome. If the classifier predicts whether an email is a spam or not, then it is an example of a binary classification. If we set up a model for sentiment prediction where a classifier can identify the positive, negative, and neutral sentiments in a given text, it is a multi-class classifier. 
Classification is a supervised machine learning technique used to categorize or assign data points into predefined classes based on their features or attributes. Classifier is trained on a labeled data set. Example: Spam classifier for emails, the output would be binary, that is, if a mail is spam or not.
Machine learning algorithm used for classification: Logistic regression. Logistic regression helps in predicting if something is True or False instead of predicting something continuous such as the house prices. Unlike linear regression, which uses a straight line to fit the data, logistic regression fits an S-shaped curve to the data, called the sigmoid function to fit the data. The sigmoid function takes any real valued number and squashes it into a range between 0 and 1. This property is essential for interpreting the output as a probability. Output from the sigmoid function is to be compared with a threshold value of, say 0.5. While predicting the probability of a student passing or failing the test is computed. If output is more than 0.5, it would be classified as a pass, and if less than 0.5, it will be classified as fail.




   7. Unsupervised learning
Unsupervised machine learning is a type of machine learning where there are no labeled outputs. The algorithm learns the patterns and relationships in the data and groups similar data items. In unsupervised learning, the patterns in the data are explored explicitly without being told what to look for. 
Clustering is the method of grouping data items based on similarities. Within a cluster, the data items are more similar than the items outside the cluster. If some data items do not fall within any cluster, these data items are deemed as outlier points. Use cases:
The first use case of unsupervised machine learning is market segmentation. In market segmentation, one example is providing the purchasing details of an online shop to a clustering algorithm. Based on the items purchased and purchasing behavior, the clustering algorithm can identify customers based on the similarity between the products purchased.
Market segmentation
Action:
* Input is purchasing details.
* Identify similar customers based on purchasing behavior.
Output:
* Target advertisements


The second use case is on outlier analysis. One typical example for outlier analysis is to provide credit card purchase data for clustering. Fraudulent transactions can be detected by a bank using outliers. In some transactions, amounts are too high or recurring, it signifies an outlier.
Outlier analysis
Action:
* Input is credit card purchase details.
* Identify fraudulent transactions.
Output
* Anomaly detection


The third use case is recommendation systems. An example for recommendation systems is to provide users movie viewing history as input to a clustering algorithm. It clusters users based on the type or rating of movies they have watched. The output helps to provide personalized movie recommendations to users.
Recommendation systems
Action:
* Inputs are users’ movie viewing history
* identify users based on genre of movies watched
Output:
* Personalized movie recommendations


Steps involved in unsupervised ML:
Similarity. Similarity is how close two data points are to each other and is a value between 0 and 1. Similarity between objects decides which cluster they will fall into, and hence, important for clustering. There are various types of similarity measures used in clustering.
Just like supervised learning, unsupervised learning also follows a workflow. To cluster the data, for example, the fruits data, the following steps are followed: 
* Prepare the data: Remove missing values, normalize the data, and perform feature scaling.


* Create similarity metrics, the choice on which similarity metrics to use depends on the nature of the data and the specific clustering algorithm being used. Some common similarity metrics which are frequently used are Euclidean distance metric, Manhattan distance metric, cosine similarity metrics, and Jaccard similarity metrics.


* Run the clustering algorithm: clustering algorithms: Clustering algorithms use similarity metrics to cluster the data. The different types of clustering algorithms are partition-based, hierarchical-based, density-based, and distribution-based.


* Interpret the results and adjust your clustering: checking the quality of your clustering output is iterative and exploratory. Because there is no labeled output, clustering lacks the ground truth that can verify the output. Verify the results against expectations at the cluster level and the example level. Improving the result requires iteratively experimenting with the previous steps to see how they affect the clustering.






   8. Reinforcement learning
It is like teaching a dog new tricks, you reward it when it does something right, and over time, it learns to perform these actions to get more rewards. 
Reinforcement learning is a type of machine learning that enables an agent to learn from its interactions with the environment. Receives feedback in the form of rewards of penalties, without any labeled dataset.
Reinforcement learning examples: 
* Autonomous vehicles: the development of self-driving cars and autonomous drones rely heavily on reinforcement learning to make real-time decisions based on sensor data, traffic conditions, and safety considerations.
* Smart devices: virtual assistants like Alexa, Google Assistant, and Siri, utilize reinforcement learning to improve natural language processing and adapt to individual users' speech patterns and preferences.
* Industrial automation: In manufacturing and production processes, reinforcement learning is applied to optimize the performance of robots and control systems, leading to improved efficiency and reduced service.
* Gaming and entertainment: Mini video games, virtual reality experiences, and interactive entertainment use reinforcement learning to create intelligent and challenging computer controlled opponents. The AI characters in games learn from player’s interactions and become more difficult to beat as the game progresses.


Common RL terminology:
* Agent: Interacts with the environment, takes actions, learns from feedback.
* Environment: External system with which the agent interacts.
* State: Representation of the current situation of the environment at a particular time.
* Actions: Possible moves or decisions that the agent can take in each state.
* Policy: Mapping that the agent uses to decide which action to take in a given state.
The goal for Reinforcement learning algorithms is to find a policy that will yield a lot of rewards for the agent.
The optimal policy is learned through training by using algorithms like Q learning or Deep Q learning.


















3. DL FOUNDATIONS


3.1 Intro to Deep Learning
Deep learning is a subset of Machine Learning that focuses on training Artificial Neural Networks (ANNs) with multiple layers. For example, image classification.
 A very important quality of the ANN is that it can process raw data like pixels of an image and extract patterns from it. These patterns are treated as features to predict the outcomes.Allows them to automatically learn and extract intricate representations from data.
ML needs us to specify features while we train the machine learning algorithm. 
With deep learning, features are automatically extracted from the data. 
Internal representations of features and their combinations are built to predict outcomes by deep learning algorithms. This may not be feasible manually.
Deep learning algorithms allow parallel processing of data. For this, usually, data is split into small batches and process in parallel so these algorithms can process large amounts of data in a short time to learn the features and their combinations.
This leads to scalability and performance. 
In short, deep learning complements machine learning algorithms for complex data for which features cannot be described easily.


Brief History of Deep Learning
Some of the deep learning concepts like artificial neuron, perceptron, and multi-layer perceptron existed as early as 1950s. One of the most important concept of using backpropagation for training came in 1980s. In 1990s, convutional neural networks were also introduced for image analysis task. Starting 2000, GPUs(Graphics Processing Units) were introduced, and 2010 onwards GPUs became cheaper and widely available. This fueled the widespread adoption of deep learning uses like computer vision, natural language processing, speech recognition, text translation, and so on. In 2012, major networks like AlexNet and Deep Q-Network were built. 2016 onward, generative use cases of the deep learning also started to come up. Today, we have widely adopted deep learning for a variety of use cases, including LLM and many other types of generative models.




Types of Deep Learning Algorithms
Deep learning algorithms are targeted at a variety of data and applications. For data, we have images, videos, text, and audio. 
For images, applications can be image classification, object detection, and so on. 
For textual data, applications are to translate the text or detect a sentiment of a text.
For audio, the applications can be music generation, speech to text, and so on.


For image, tasks like image classification, object detection, image segmentation, or facial recognition, CNN is a suitable architecture. For text, we have a choice of the latest transformers or LSTM(Long-Short-Term Memory) or RNN(Recurrent Neural Networks). For a generative task like text summarization, question answering, transformers is a good choice. For generating images, texto text image generation, transformers,  generative Adversarial Networks(GAN) or diffusion models are available choice.


What is Artificial Neural Network (ANN)? Inspired by the human brain. They are made up of interconnected nodes called as neurons.
How inputs are processed by a neuron? In ANN we assign weights to the connection between neurons. Weighted inputs are added up and if the sum crosses a specified threshold, the neuron is fired, and the outputs of a layer of neuron become an input to another layer.


Building blocks of ANN:
* Layers: Input, hidden(hidden layers are optional), and output layers receive inputs, transform it and produce output.
* Neurons: Neurons are computational units, which accept an input and produce an output.
* Weights: Determines the strength of connection between neurons, so the connection could be between input and a neuron, or it could be between neuron and another neuron.
* Activation Function: Works on the weighted sum of inputs to a neuron and produces an output.
* Bias: Additional input to a neuron that allows certain degree of flexibility.


How are ANNs trained? Learn using backpropagation algorithm. During training, we show an image to the ANN, let us say it is an image of digit 2, so we expect output neuron for digit 2 to fire. But in real, let us say output neuron of a digit 6 fired. We know that there is an error. So to correct an error we adjust the weights of the connection between neurons based on a calculation, which we call as backpropagation algorithm by showing thousands of images and and adjusting the weights iteratively, ANN is able to predict correct outcome for most of the input images. This process is called model training.
  











3.2. Deep Learning Models-Sequence Models
Sequence models are used to solve problems where the input data is in the form of sequences. The sequences are ordered, lists of data points and events. The goal in sequence models is to find patterns and dependencies within data and make predictions, classifications, or even generate new sequences. Some common examples of the sequence models are:
*  In natural language processing, deep learning models are used for tasks such as machine translation, sentiment analysis, or text generation.
* In speech recognition, deep learning models are used to convert recorded audio in a text.
* And deep learning models can generate new music or create original compositions.
* Even sequences of hand gestures are interpreted by deep learning models for applications like sign language recognition.
* In fields like finance or weather prediction, time series data is used to predict future values.




What is a Recurrent Neural Network(RNN)? RNN are a class of neural network architectures specifically designed to handle sequential data. 
Unlike traditional feedforward neural networks, RNN have a feedback loop that allows information to persist across different timesteps.
The key features of RNN is their ability to maintain an internal state, often referred to as a hidden state or memory, which is updated as the network processes each element in the input sequence. The hidden state is then used as input to the network for the next time step, allowing the model to capture dependencies and patterns in the data that are spread across time.


Types of RNN Architecture
There are different types of RNN architecture based on application:
* One of them is one-to-one. This is like a feedforward neural network and is not suited for sequential data.
* A one-to-many model produces multiple output values for one input value. Music generation or sequence generation are some applications using this architecture.
* A many-to-one model produces one output value after receiving multiple input values. An example is sentiment analysis based on the review.
* Many-to-many model produce multiple output values for multiple input values. Examples are machine translation and named entity recognition.
RNN does not perform that well when it comes to capturing long term dependencies. This is due to the vanishing gradients problem, which is overcome by using LSTM model.


What is Long Short-Term Memory? works by using a specialized memory cell and a gating mechanism to capture long-term dependencies in the sequential data. The key idea behind LSTM is to selectively remember or forget information over time, enabling the model to maintain relevant information over long sequences which helps overcome the vanishing gradients problem.




Step-by-step working of LSTM
* At each timestep, the LSTM takes an input vector representing the current data point in the sequence.
* The LSTM also receives the previous hidden state and cell state. These represent what the LSTM has remembered and forgotten up to the current point in the sequence.
* The core of the LSTM lies in its gating mechanisms, which include 3 gates: the input gate, the forget gate, and the output gate. These gates are like the filters that control the flow of information within the LSTM cell. THe input gate decides what new information from the current input should be added to the memory cell. The forget gate determines what information in the current memory cell should be discarded or forgotten. The output gate regulates how much of the current memory cell should be exposed as the output of the current time step.
* Using the information from the input gate and forget gate, the LSTM updates its cell state. 
* The LSTM then uses the output to produce the current hidden state, which becomes the output of the LSTM for the next time step.






3.2 Deep Learning Models-CNN(Convolutional Neural Networks)
Deep Learning model architectures. 
-The first one is Feedforward Neural Networks, abbreviated as FNN. This is also called as Multilayer Perceptron(MLP), and is the simplest form of neural networks.
- Second is CNN, which is Convolutional Neural Network. This can automatically detect and learn local patterns and features in images and videos. 
- The third one is RNN, which is a recurrent neural network. RNN are designed to handle sequential data, such as time series data or natural language. They have a feedback loop that allows them to maintain hidden states and capture temporal dependencies.
- The fourth one is autoencoders. Autoencoders are unsupervised learning models used for feature extraction and dimensionality reduction, and is commonly employed in data compression and anomaly detection.
- The fifth one is LSTM or Long Short-Term Memory, specialized RNN variant designed to handle long-term dependencies in sequential data.
- The sixth one is GAN, which is generative adversarial network. This is a powerful machine learning model which is used for generating realistic synthetic data such as images, audio, and text.
- The last one is Transformers. Transformers are widely used in NLP and have become state of the art models for tasks like machine translation, text generation, and language understanding.


What is a Convutional Neural Network?
CNN is a type of deep learning model specifically designed for processing grid-like data such as images and videos. In the ANN, which was seen in the previous lesson, the input image is converted to a single dimensional array and given as an input to the network. But that does not work well with the image data, because image data is inherently two dimensional.
CNN works better with 2 dimensional data. The role of CNN is to reduce an image into a form, which is easier to process and without losing features, which are critical for getting a good prediction.


CNN Layers - Overview
The first one is Input Layer. Accepts 3D images with height, width, and depth representing RGB color channels.
Input layer is followed by feature extraction layers, which is a combination and repetition of multiple feature extraction layers, including convolutional layer with ReLu activation and a pooling layer. The feature extraction layers play a vital role in image classification.
Classification Layers. Fully connected output layer, where classification occurs.


To summarize, the purpose of feature extraction layers is to automatically learn and extract relevant patterns and features from the input images. 
Convolutional layer applies convolutional operations to the input image using small filters known as kernels. Each filter slides across the input image using small filters known as kernels to detect specific features, such as edges, corners, or textures.
The second one is the activation function, which is applied after each convolutional operation. The activation function allows the network to learn more complex and non-linear relationships in the data.
And the third one is pooling. It helps reduce computational complexity and also reduces the spatial dimensions of the feature maps generated by the convolutional layers.


Limitations of CNN
* Computation: Requires massive data and computations.
* Overfitting: Happens with limited training data.
* Interpretability: CNNs are considered black box models, making it difficult to interpret.
* Sensitivity: Highly sensitive to input variations.


Applications of CNN: Image Classification, Object Detection, Pixel level segmentation, Face Recognition, Medical Imaging, Autonomous Vehicles, Remote Sensing.


4. Gen AI and LLM Foundations
4.1 Intro to Gen AI
AI is the ability of machine learning to imitate human intelligence. 
Machine learning is a subset of AI where algorithms are used to learn from past data, and predict outcome on new data, or to identify trends from the past data.
Deep learning is a further subset of machine learning in which algorithms are modeled to learn from complex data using neural networks.
Generative AI is a type of AI that can create new content. Includes models that can create a wide range of outputs such as text, images, music, videos, and other types of data. Gen AI is a subset of deep learning where the models are trained to generate output on their own. GenAI unlocks exciting possibilities for creative tasks, automation, and new ideas.


How does GenAI work? Gen AI model learns the underlying patterns in a given data set and uses that knowledge to create new data that shares those patterns.


How does it compare to ML? ML is about identifying patterns and using those patterns to recognize and classify new examples of cats and dogs. Machine learning starts with the model being trained with the training data set. But now the training data set consists of a set of input features and output labels, so what we refer to as data and labels on this slide. In dogs and cats pics it could be body shape, skin texture, eye color, etc. But in Machine Learning we also provide a corresponding output label. 
During the process of training, ml model learns the relationship between input features and the corresponding output labels from the provided data. Once the model learns from this data, we have what we refer to as a trained model. After the model is trained, it can be used for making predictions, or what we refer to as inference. Inference is a process of getting a prediction by giving a new data point. So in this example, we provide a pic of a cat or a dog(without label), and the trained model predicts the output is a dog. This is a type of machine learning which is referred to as supervised learning.


How is Generative AI different from other AI approaches? In the case of a traditional machine learning model, the model learns the relationship between data and label, and the output is a label, a prediction, or a classification. In the case of a GenAI model, the model is learning patterns in unstructured content. Unlike traditional Machine learning models Gen AI models don’t require labeled data in its pre-training state. It is pre-trained on unlabeled data. A pre-trained GenAI model can be further trained on a labeled data set to obtain what we refer to as a fine-tuned model for specific tasks. But at the moment let’s assume that the GenAI models are learning patterns based on unstructured content.
Also, the use cases are different. A traditional machine learning model can be used for classification, regression, recommendation systems, making predictions etc. A GenAI model is used for generation, like text generation, or it could be any kind of media generation.


Types of Gen AI models
Two main types of GenAI models: 
The first type is text-based, where models can generate text, code, dialogues or chat, or articles. In this case, the models are learning from large collections of text data to capture patterns, language structures, and semantic relationships.
The second kind of GenAI models are what we refer to as multimodal models. These are the models which are capable of processing and generating multiple modalities and learning from multiple modalities simultaneously. These modalities could include text, images, audio, and video.




Generative AI applications
Image and video generation, creative content generation, data augmentation and synthesis, medical imaging and drug discovery, natural language processing.






4.2 Intro to LLM
What is a LLM? A language model (LM) is a probabilistic model of text that determines the probability of a given sequence of words occurring in a sentence based on the previous words. It helps to predict which word is more likely to appear next in the sentence.


It is important to know that when we run a sequence of words through a language model, we are going to get a probability for every single word in its vocabulary, but no words outside of its vocabulary. 
When we refer to these language models, we always refer to them as large language models. The large in the large language models refers to the number of parameters. There is no agreed upon threshold upon which a model becomes large or small, but these models all together are referred to as large language models. 
The word to pick is the one with highest probability in a sentence.
  



Large Language Model Examples
You can ask questions to a LLM and it can answer questions. You can ask it to write an article or essay, you can ask it to translate text…


Large Language Model Features
LLM  are based on a deep learning architecture called Transformer. This allows them to pay selective attention to different parts of the input when making the next word prediction. This gives LLMs enhanced contextual understanding. These models have shown remarkable capabilities in natural language understanding and perform very well in various NLP tasks such as question answering, language translation, which we saw in the previous slide, sentiment analysis, summarization, etcetera.
GenAI and LLM are part of a subset of deep learning. LLM are deep neural networks trained on massive amounts of text data consisting of large portions of the entire publicly available text on the internet. The parameters for models can scale from hundreds of millions to billions of parameters.


Model Size and Parameters
These parameters are nothing but adjustable weights in the neural network that are optimized during training to predict the next word in a sequence. Model size refers to the amount of memory required to store the model’s parameters and other data structures. But having a large number of parameters does not necessarily translate to better performance on any given task, in fact if a model is too large and has too many parameters, it can potentially overfit to the training data.


To wrap up LLM is a probabilistic model of text that determines the probability of a given sequence of words occurring in a sentence based on the previous words. 
These LLM are based on a deep learning architecture called transformer.










4.3 Transformers (Part 1)
Understanding Language for machines can be tricky.
We have used a kind of an architecture called recurrent neural networks, RNN, for handling sequential data. RNN - used for input data (sequence).
RNNs are a class of neural network architectures specifically designed to handle sequential data. RNNs have a feedback loop that allows info to persist across different time steps, making them well suited for tasks involving sequence of data or sequence of text.
A key feature of RNN is their ability to maintain an internal state, often referred to as the hidden state or memory, which is updated as the network processes each element in the sequence. The hidden state is then used as input to the network for the next time step, allowing the model to capture dependencies and patterns in the data that are spread across time.
While this works well for short sequences, it becomes problematic when dealing with long sentences or entire documents. RNNs process input data one element at a time, maintaining a hidden state. Because of this limitation, RNNs can only capture dependencies between nearby words and struggle to connect words that are farther apart in the sentence. As the sequence grows , the model's ability to retain relevant context and dependency weakens, leading to a phenomenon called vanishing gradient. And long-range dependencies become challenging to capture, limiting RNN’s understanding of the entire sequence. This has been a challenge with architectures such as recurrent neural networks.


Transformers understand relationships between all the words in a sentence. Transformers can look at all the words in the sentence at the same time and understand how they relate to each other. It allows to understand the sentence as a whole instead of just a series of individual words like RNNs would.


Attention Mechanism (also known as self-attention mechanism): adds context to the Text


Transformers is a type of deep learning model that was introduced in the paper “Attention is all you need”  introduced by Vaswany in 2017, it differs significantly from RNN (and LSTM) models.
Self-attention mechanism which helps in determining the relevance and importance of each word in a sequence.
The transformer architecture has two submodules, an encoder and a decoder. The encoder module processes the input text and encodes into a series of numerical representations, also referred to as vectors that capture the contextual information of the input. The decoder module takes these encoded vectors and generates the output text. Both the encoder and the decoder consist of many layers connected by the self-attention mechanism.